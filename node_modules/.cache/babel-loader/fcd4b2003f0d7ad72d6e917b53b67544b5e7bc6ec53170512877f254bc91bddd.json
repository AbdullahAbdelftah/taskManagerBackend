{"ast":null,"code":"import { config } from \"dotenv\";\nconfig();\nimport OpenAI from 'openai';\nconst openai = new OpenAI({\n  apiKey: process.env.API_KEY // This is also the default, can be omitted\n});\nasync function gpt(msg) {\n  const chatCompletion = await openai.chat.completions.create({\n    model: \"gpt-3.5-turbo\",\n    messages: [{\n      \"role\": \"user\",\n      \"content\": msg\n    }]\n  });\n  return chatCompletion.choices[0].message.content;\n}\nexport { gpt };","map":{"version":3,"names":["config","OpenAI","openai","apiKey","process","env","API_KEY","gpt","msg","chatCompletion","chat","completions","create","model","messages","choices","message","content"],"sources":["D:/HTML and CSS/task-manager/src/openai/openai.js"],"sourcesContent":["import {config} from \"dotenv\" \r\nconfig()\r\nimport OpenAI from 'openai';\r\nconst openai = new OpenAI({\r\n    apiKey: process.env.API_KEY // This is also the default, can be omitted\r\n});\r\nasync function gpt(msg){\r\n    const chatCompletion = await openai.chat.completions.create({\r\n        model: \"gpt-3.5-turbo\",\r\n        messages: [{\"role\": \"user\", \"content\": msg}],\r\n      });\r\n      return chatCompletion.choices[0].message.content;\r\n}\r\nexport {gpt}"],"mappings":"AAAA,SAAQA,MAAM,QAAO,QAAQ;AAC7BA,MAAM,CAAC,CAAC;AACR,OAAOC,MAAM,MAAM,QAAQ;AAC3B,MAAMC,MAAM,GAAG,IAAID,MAAM,CAAC;EACtBE,MAAM,EAAEC,OAAO,CAACC,GAAG,CAACC,OAAO,CAAC;AAChC,CAAC,CAAC;AACF,eAAeC,GAAGA,CAACC,GAAG,EAAC;EACnB,MAAMC,cAAc,GAAG,MAAMP,MAAM,CAACQ,IAAI,CAACC,WAAW,CAACC,MAAM,CAAC;IACxDC,KAAK,EAAE,eAAe;IACtBC,QAAQ,EAAE,CAAC;MAAC,MAAM,EAAE,MAAM;MAAE,SAAS,EAAEN;IAAG,CAAC;EAC7C,CAAC,CAAC;EACF,OAAOC,cAAc,CAACM,OAAO,CAAC,CAAC,CAAC,CAACC,OAAO,CAACC,OAAO;AACtD;AACA,SAAQV,GAAG"},"metadata":{},"sourceType":"module","externalDependencies":[]}